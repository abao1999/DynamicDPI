{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f1d1a67",
   "metadata": {},
   "source": [
    "# Starwarps Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b2aad0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to eht-imaging! v 1.2.2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note: this is an example sequence of commands to run in ipython that generates a movie\n",
    "# from a single night of observation. \n",
    "#\n",
    "# Contact Katie Bouman (klbouman@mit.edu) for any questions \n",
    "#\n",
    "# The methods/techniques used in this, referred to as StarWars, are described in \n",
    "# \"Reconstructing Video from Interferometric Measurements of Time-Varying Sources\" \n",
    "# by Katherine L. Bouman, Michael D. Johnson, Adrian V. Dalca, \n",
    "# Andrew Chael, Freek Roelofs, Sheperd S. Doeleman, and William T. Freeman\n",
    "\n",
    "# Note: must import ehtim outside the ehtim directory\n",
    "# either in parent eht-imaging directory or after installing with setuptools\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import ehtim as eh\n",
    "from   ehtim.calibrating import self_cal as sc\n",
    "from ehtim.imaging import patch_prior as pp\n",
    "import ehtim.image as image\n",
    "from ehtim.imaging import starwarps as sw\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os, copy\n",
    "import scipy\n",
    "import scipy.optimize as opt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020730c3",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83e0f95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset  DPI_dev.yml  DPItorch\tDPI.yml  DynamicDPItorch  README.md  scripts\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dffd4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file\n",
    "obsname = '../dataset/interferometry1/obs.uvfits'\n",
    "\n",
    "# image parameters\n",
    "flux = 2.0\n",
    "fwhm = 50 * eh.RADPERUAS\n",
    "fov = 100 * eh.RADPERUAS\n",
    "NPIX = 30\n",
    "npixels = NPIX**2\n",
    "\n",
    "# StarWarps optimization parameters\n",
    "warp_method = 'phase'\n",
    "measurement = {'vis':1 } # {'amp':1, 'cphase':1}\n",
    "interiorPriors = True\n",
    "reassign_apxImgs = False\n",
    "numLinIters = 5\n",
    "variance_img_diff = 1e-7\n",
    "\n",
    "# parameters associated with EM \n",
    "nIters = 30\n",
    "NHIST = 5000\n",
    "stop=1e-10\n",
    "maxit=4000\n",
    "\n",
    "# directory where to save results\n",
    "SAVE = True\n",
    "dirname = '../results'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71440c4",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11271241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading uvfits:  ../dataset/interferometry1/obs.uvfits\n",
      "POLREP_UVFITS: circ\n",
      "Number of uvfits Correlation Products: 4\n",
      "No NX table in uvfits!\n",
      "Splitting Observation File into 100 scans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abao/anaconda3/envs/dpi_torch_dev/lib/python3.7/site-packages/ehtim/obsdata.py:508: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(datalist)\n"
     ]
    }
   ],
   "source": [
    "# load in the data\n",
    "obs = eh.obsdata.load_uvfits(obsname)\n",
    "\n",
    "# split the observations based upon the time\n",
    "obs_List = sw.splitObs(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea47a43c",
   "metadata": {},
   "source": [
    "## Reconstruct movie with no warp field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd0cdda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Forward timestep 0 of 100 total timesteps..."
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1d684bacebb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mmeanImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimCov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_List\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoiseCov_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitTheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mflowbasis_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflowbasis_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitTheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarp_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeasurement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     interiorPriors=interiorPriors, numLinIters=numLinIters, compute_expVal_tm1_t=False)\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# save out results as a movie\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dpi_torch_dev/lib/python3.7/site-packages/ehtim/imaging/starwarps.py\u001b[0m in \u001b[0;36mcomputeSuffStatistics\u001b[0;34m(mu, Lambda, obs_List, Upsilon, theta, init_x, init_y, flowbasis_x, flowbasis_y, initTheta, init_images, method, measurement, lightcurve, interiorPriors, numLinIters, compute_expVal_tm1_t, mask, normalize)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUpsilon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mloglikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_t_tm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_t_tm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_t_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_t_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapxImgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforwardUpdates_apxImgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_List\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeasurement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlightcurve\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlightcurve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteriorPriors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minteriorPriors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumLinIters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumLinIters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minteriorPriors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dpi_torch_dev/lib/python3.7/site-packages/ehtim/imaging/starwarps.py\u001b[0m in \u001b[0;36mforwardUpdates_apxImgs\u001b[0;34m(mu, Lambda_orig, obs_List, A_orig, Q_orig, init_images, measurement, lightcurve, numLinIters, interiorPriors, mask, normalize)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumLinIters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;31m# F is the derivative of the Forward model with respect to the unknown parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mmeas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midealmeas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasCov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetMeasurementTerms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_List\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_List_lin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeasurement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtot_flux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlightcurve\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0mz_List_t_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_List_t_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprodGaussiansLem2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasCov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_star_List_t_tm1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_star_List_t_tm1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# initialize the mean and the image covariance for the prior. \n",
    "# this can be a single image to be the same mean and covariance for each \n",
    "# time, or different for each time by appending an image/matrix for each timestep\n",
    "\n",
    "# initialize mean\n",
    "meanImg = []\n",
    "emptyprior = eh.image.make_square(obs, NPIX, fov)\n",
    "gaussprior = emptyprior.add_gauss(flux, (fwhm, fwhm, 0, 0, 0))\n",
    "meanImg.append(gaussprior.copy())\n",
    "\n",
    "# initialize covariance\n",
    "imCov = []\n",
    "imCov.append( sw.gaussImgCovariance_2(meanImg[0], powerDropoff=2.0, frac=1./2.) )\n",
    "\n",
    "# make the covariance matrix that says how much variation there should be between frames in time \n",
    "noiseCov_img = np.eye(npixels)*variance_img_diff\n",
    "\n",
    "# initialize the flowbasis and get the initTheta which says how to specify no motion for the specified flow basis\n",
    "init_x, init_y, flowbasis_x, flowbasis_y, initTheta = sw.affineMotionBasis_noTranslation(meanImg[0])\n",
    "\n",
    "# run StarWarps to find the distribution of the image at each timestep\n",
    "expVal_t, expVal_t_t, expVal_tm1_t, loglikelihood, apxImgs = sw.computeSuffStatistics(\n",
    "    meanImg, imCov, obs_List, noiseCov_img, initTheta, init_x, init_y, \n",
    "    flowbasis_x, flowbasis_y, initTheta, method=warp_method, measurement=measurement, \n",
    "    interiorPriors=interiorPriors, numLinIters=numLinIters, compute_expVal_tm1_t=False)\n",
    "\n",
    "# save out results as a movie\n",
    "if SAVE:\n",
    "    # make the directory to save out the results\n",
    "    try:\n",
    "        os.stat(dirname)\n",
    "    except:\n",
    "        os.mkdir(dirname)\n",
    "    \n",
    "    # save out the movie that is generated assuming there is no motion\n",
    "    sw.movie(expVal_t, out = dirname + '/movie_nomotion.mp4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d2050e",
   "metadata": {},
   "source": [
    "## Learn warp field and reconstruct movie using derived EM-algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of motion parameters\n",
    "nbasis = flowbasis_x.shape[2] \n",
    "\n",
    "# set the bounds for the motion parameters\n",
    "bnds = []\n",
    "for b in range(0,nbasis):\n",
    "    bnds.append( (-1.5,1.5) )\n",
    "\n",
    "\n",
    "# initialize optimization parameters\n",
    "newTheta = copy.deepcopy(initTheta)\n",
    "feval = 0.0\n",
    "optdict = {'maxiter':maxit, 'ftol':stop, 'maxcor':NHIST, 'disp':True} # minimizer params\n",
    "negll = []\n",
    "thetas = []\n",
    "fevals = []\n",
    "\n",
    "for iter in range(0, nIters+1):\n",
    "\n",
    "    print('\\rIteration %i of %i ...' % (iter, nIters+1) )\n",
    "    \n",
    "    # ========== E-step ========== #\n",
    "    if iter==0 or reassign_apxImgs:\n",
    "        apxImgs = False\n",
    "\n",
    "    # solve for the sufficient statistics using the StarWarps approach with the previous value \n",
    "    # the warp parameters in newTheta\n",
    "    expVal_t, expVal_t_t, expVal_tm1_t, loglikelihood, apxImgs = sw.computeSuffStatistics(\n",
    "        meanImg, imCov, obs_List, noiseCov_img, newTheta, init_x, init_y, \n",
    "        flowbasis_x, flowbasis_y, initTheta, method=warp_method, measurement=measurement, \n",
    "        interiorPriors=interiorPriors, numLinIters=numLinIters, apxImgs=apxImgs)\n",
    "\n",
    "    # save the negative log likelihood (nll), the value of the warp parameters (thetas) \n",
    "    # and the evaluation of the optimization function (feval)\n",
    "    negll.append(-loglikelihood[2])\n",
    "    thetas.append(newTheta)\n",
    "    fevals.append(feval)\n",
    "    \n",
    "    # ========== visualize and save results ========== #\n",
    "    \n",
    "    if SAVE: \n",
    "    \n",
    "        # make the directory to save out the results\n",
    "        try:\n",
    "            os.stat(dirname + '/' + str(iter))\n",
    "        except:\n",
    "            os.mkdir(dirname + '/' + str(iter))\n",
    "    \n",
    "        # save frames as the mean and the estimated standard deviation of each frame\n",
    "        stdevImg = meanImg[0].copy()\n",
    "        for i in range(0,len(obs_List)):\n",
    "            stdevImg.imvec = np.sqrt(np.diag(expVal_t_t[i]))\n",
    "            expVal_t[i].save_fits(dirname + '/' + str(iter) + '/mean_' + str(i) + '.fits')\n",
    "            stdevImg.save_fits(dirname + '/' + str(iter) +  '/stdev_' + str(i) + '.fits')\n",
    "\n",
    "        # compute the average image\n",
    "        avgImg = meanImg[0].copy()\n",
    "        avgImg.imvec = np.mean([im.imvec for im in expVal_t],axis=0)\n",
    "    \n",
    "        #save flow diagram\n",
    "        plt.figure(), sw.plot_Flow(avgImg, thetas[iter], init_x, init_y, flowbasis_x, flowbasis_y, initTheta, step=1)\n",
    "        plt.savefig(dirname + '/flow_' + str(iter) +  '.pdf')\n",
    "\n",
    "        #save a movie\n",
    "        sw.movie(expVal_t, dirname + '/movie_' + str(iter) + '.mp4')\n",
    "\n",
    "        # save out mat file with the information\n",
    "        scipy.io.savemat(dirname + '/info_' + str(iter) + '.mat', {'negll':negll, 'thetas':thetas, 'funeval':fevals})\n",
    "    \n",
    "    # ========== M-step ========== #\n",
    "    if iter < nIters:\n",
    "        result = opt.minimize(sw.expnegloglikelihood, newTheta, args=(expVal_t, expVal_t_t, expVal_tm1_t, meanImg, imCov, obs_List, noiseCov_img, init_x, init_y, flowbasis_x, flowbasis_y, initTheta, warp_method), method='L-BFGS-B', jac=sw.deriv_expnegloglikelihood, bounds=bnds, options=optdict)\n",
    "        newTheta = result.x\n",
    "        feval = result.fun\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
